===>train_size:  11314
===>test_size:  7532
===>vocab_size:  5000
===>average length: 110.543
Load pretrained glove embeddings from : glove.6B.100d.txt
num-trained in voc_size: 4957|5000: 0.9914
topic_layer.weight
InferNet.encoder.0.weight
InferNet.encoder.0.bias
InferNet.encoder.3.weight
InferNet.encoder.3.bias
InferNet.encoder.5.weight
InferNet.encoder.5.bias
===>using lr_scheduler
/mnt/miniconda3/envs/ducnq_topmost/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
  0%|                                                    | 0/10 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/mnt/tungns/Baselines/main.py", line 131, in <module>
    trainer.train(dataset)
  File "/mnt/tungns/Baselines/basic_trainer.py", line 437, in train
    rst_dict = self.model(train_data, bow )
  File "/mnt/miniconda3/envs/ducnq_topmost/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/mnt/miniconda3/envs/ducnq_topmost/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/tungns/Baselines/models/WETE.py", line 227, in forward
    self.update_embeddings()
  File "/mnt/tungns/Baselines/models/WETE.py", line 181, in update_embeddings
    self.rho = self.word_layer(self.word_id).squeeze()
  File "/mnt/miniconda3/envs/ducnq_topmost/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/mnt/miniconda3/envs/ducnq_topmost/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/miniconda3/envs/ducnq_topmost/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 164, in forward
    return F.embedding(
  File "/mnt/miniconda3/envs/ducnq_topmost/lib/python3.10/site-packages/torch/nn/functional.py", line 2267, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)
